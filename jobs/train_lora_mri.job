#!/usr/bin/env bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=LoRA-MRI
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --time=00:59:00
#SBATCH --mem=32000M
#SBATCH --output=/home/scur0402/jobs/logs/LoRA-MRI_%A.out

date

export HF_DATASETS_CACHE=/scratch-shared/scur0402/hf_cache_dir

WORK_DIR=$HOME/danilo/adapt_med_seg
cd $WORK_DIR


module purge
module load 2023
source $WORK_DIR/.venv/bin/activate

# Danilo: 1h trainig job time went up to epoch 27
python -m adapt_med_seg.train \
    --model_name "segvol_lora" \
    --dataset_path /scratch-shared/scur0402/datasets \
    --epochs 100 \
    --lora_r 16 \
    --lora_alpha 16 \
    --ckpt_path /home/scur0402/danilo/adapt_med_seg/logs/lightning_logs/version_4/checkpoints/epoch=79-step=16000.ckpt