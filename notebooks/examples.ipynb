{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegVol inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Matey/miniconda3/envs/SegVol/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/Matey/project/adapt_med_seg/datasets/0000.zip created.\n",
      "Downloading https://huggingface.co/datasets/GoodBaiBai88/M3D-Seg/resolve/main/M3D_Seg/0000.zip?download=true to /Users/Matey/project/adapt_med_seg/datasets/0000.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71093it [00:58, 1220.00it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/Matey/project/adapt_med_seg/datasets/0000.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:adapt_med_seg.pipelines.evaluate:Evaluating segvol_baseline on dataset 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to /Users/Matey/project/adapt_med_seg/datasets\n",
      "File downloaded and saved as 0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CHAOS: 100%|██████████| 4/4 [06:27<00:00, 96.92s/batch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for segvol_baseline on dataset 0:\n",
      "{'dice': tensor(0.9659)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from adapt_med_seg.pipelines.evaluate import EvaluateArgs, EvaluatePipeline\n",
    "\n",
    "model_names = [\"segvol_baseline\"]\n",
    "dataset_numbers = [0]\n",
    "\n",
    "for model_name in model_names:\n",
    "    for dataset_number in dataset_numbers:\n",
    "        eval_pipeline = EvaluatePipeline(\n",
    "            evaluate_args=EvaluateArgs(\n",
    "                dataset_number=dataset_number,\n",
    "                model_name=model_name,\n",
    "                cls_idx=0,\n",
    "                device='cpu'\n",
    "                # use_wandb=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        results = eval_pipeline.run()\n",
    "        print(f'Results for {model_name} on dataset {dataset_number}:\\n{results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegVol vanilla training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt_med_seg.data.dataset import MedSegDataset\n",
    "from adapt_med_seg.pipelines.train import SegVolLightning, TrainingArgs\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "model_names = [\"segvol_baseline\"]\n",
    "dataset_numbers = [0]\n",
    "\n",
    "for model_name in model_names:\n",
    "    for dataset_number in dataset_numbers:\n",
    "        training_args = TrainingArgs(\n",
    "            dataset_number=dataset_number,\n",
    "            model_name=model_name,\n",
    "            cls_idx=0,\n",
    "            device=\"cpu\",\n",
    "            # use_wandb=True,\n",
    "        )\n",
    "\n",
    "        train_pipeline = SegVolLightning(model_name)\n",
    "\n",
    "        _dataset = MedSegDataset(\n",
    "            dataset_number=dataset_number,\n",
    "            processor=train_pipeline._model.processor,\n",
    "            train=True,\n",
    "        )\n",
    "\n",
    "        train_pipeline.set_dataset(_dataset)\n",
    "        train_dataloader, val_dataloader = _dataset.get_train_val_dataloaders(\n",
    "            1 / 9, 1, 42\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            max_epochs=10,\n",
    "            accelerator=training_args.device,\n",
    "            deterministic=True,\n",
    "            num_sanity_val_steps=0,\n",
    "        )\n",
    "        trainer.fit(train_pipeline, train_dataloader, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
